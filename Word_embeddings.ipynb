{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D73T1cuBg4a6",
        "outputId": "48a7be9b-56b2-4981-b48a-c4e8c3e2e65f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "Shape of word embeddings: (10000, 50)\n",
            "Word embeddings:\n",
            "Word index 0: [ 0.04807285 -0.00058662 -0.02820878  0.00674134 -0.00417324 -0.00750982\n",
            " -0.04809252  0.03454049  0.03716179  0.02109833 -0.00994356  0.00430143\n",
            " -0.03056931  0.02417031 -0.04226265 -0.04880222  0.0161747  -0.04533769\n",
            " -0.03015019 -0.01227547 -0.02249843  0.04098021  0.018321    0.02507835\n",
            "  0.02979488 -0.01860898  0.0346786   0.01216443  0.04781118 -0.02494792\n",
            " -0.00943723  0.0023643  -0.04260791 -0.02103874  0.02855989  0.01246569\n",
            " -0.03425239  0.02199224  0.02656057  0.0222691   0.04237549 -0.04094536\n",
            "  0.00415481  0.03114421  0.01289362  0.03970803 -0.03114772  0.01770026\n",
            " -0.01431429 -0.02203734]\n",
            "Word index 1: [ 0.04478847 -0.04664689  0.01623667 -0.00425769  0.00750063  0.03441974\n",
            " -0.00785174  0.04170359  0.01049595  0.04825724 -0.04421037  0.0131147\n",
            "  0.0363943  -0.01426922 -0.01300881  0.0016926   0.00959295  0.03108868\n",
            " -0.01910365 -0.00057612 -0.03238225 -0.01102386 -0.00180739  0.01685617\n",
            " -0.00744829  0.02668785  0.03384491 -0.02804781  0.00898491 -0.04284209\n",
            "  0.01479114  0.03288579 -0.04241134 -0.04662483 -0.04736639 -0.03143223\n",
            "  0.04598803  0.02111849  0.01850611  0.0279797   0.02339316 -0.00548698\n",
            " -0.00376371  0.01012865  0.02496943 -0.03670504 -0.03819696 -0.02370921\n",
            "  0.03395796 -0.02473118]\n",
            "Word index 2: [ 0.0314597  -0.0080904  -0.03997277  0.01802423 -0.03317634 -0.01901317\n",
            " -0.03332406 -0.02603102  0.03071428 -0.0452759   0.04521353  0.0140324\n",
            "  0.00124154  0.04078922 -0.03652095 -0.00563328  0.01994529 -0.00656694\n",
            "  0.03939805 -0.017292   -0.01717726  0.01143957 -0.00102051  0.04056605\n",
            " -0.00566102 -0.03059559 -0.01158271  0.02699157 -0.00845562  0.02477099\n",
            " -0.0281104   0.02540005  0.00502545  0.01011568 -0.00872886  0.02352098\n",
            "  0.01314174  0.04572116  0.03577875 -0.02146726 -0.03942963  0.0364761\n",
            "  0.00699254  0.04836318  0.04681729 -0.04971374  0.02091339  0.0080669\n",
            " -0.01017853  0.01093068]\n",
            "Word index 3: [-0.01377534 -0.02908752 -0.00778069 -0.02346675 -0.04823812 -0.04279393\n",
            " -0.01798086 -0.0480707   0.038789    0.03371917  0.01969426  0.00899013\n",
            " -0.01556231 -0.02073422 -0.04257184 -0.02392156 -0.00382959  0.03874308\n",
            "  0.03998882 -0.03748419  0.0484875  -0.04177263  0.04896344  0.01653559\n",
            "  0.02634671 -0.00857963  0.04788253  0.04346787 -0.04661953  0.02012433\n",
            "  0.0395073   0.02606466 -0.02890663  0.03703338 -0.02469298  0.03940118\n",
            "  0.04070747  0.00021801  0.02844625 -0.0289175   0.00030749 -0.04837931\n",
            "  0.02126682 -0.03922309  0.00376513  0.02402662  0.00310568  0.00717776\n",
            " -0.04789314 -0.04809428]\n",
            "Word index 4: [ 0.00394902  0.0403976  -0.03450544  0.02059991  0.00436684 -0.04102065\n",
            " -0.02502956  0.04572341 -0.04593779  0.04240132 -0.0424274   0.0297146\n",
            " -0.04141725 -0.00484779 -0.04915069 -0.03628401 -0.03117791  0.00080799\n",
            " -0.02744384  0.04989251  0.04477427  0.03308118  0.04636916  0.01321267\n",
            "  0.04580444  0.0399547  -0.00115664 -0.01352122  0.03207656  0.02576833\n",
            " -0.00852025 -0.03098589  0.03025719 -0.03441877 -0.04205927 -0.00950228\n",
            " -0.01861298  0.01330991 -0.0329138  -0.0408671  -0.01655529  0.01244441\n",
            " -0.02418195  0.03352245 -0.01861912 -0.00872089 -0.04566232  0.00590379\n",
            " -0.03012337  0.04327686]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Parameters\n",
        "max_features = 10000  # Consider only the top 10,000 words in the dataset\n",
        "maxlen = 200  # Limit the maximum length of each review to 200 words\n",
        "embedding_dim = 50  # Dimensionality of the embedding space\n",
        "\n",
        "# Load the IMDB dataset\n",
        "(X_train, _), (_, _) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=maxlen))\n",
        "\n",
        "# Compile the model (not needed for printing embeddings)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Access the learned embeddings\n",
        "embeddings = model.layers[0].get_weights()[0]\n",
        "\n",
        "# Print the shape of the embeddings\n",
        "print(\"Shape of word embeddings:\", embeddings.shape)\n",
        "\n",
        "# Print the first few embeddings\n",
        "print(\"Word embeddings:\")\n",
        "for i in range(5):\n",
        "    print(f\"Word index {i}: {embeddings[i]}\")\n"
      ]
    }
  ]
}